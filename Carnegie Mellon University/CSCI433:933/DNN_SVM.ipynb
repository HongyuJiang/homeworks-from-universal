{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN_SVM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2nTKGbIDNCL"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeENRfHInjQH"
      },
      "source": [
        "# DNN-based Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN8X9kayDPKz",
        "outputId": "b41aa14d-f3a0-4dac-98d5-4615ec60ee78"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "print (x_train.shape)\n",
        "print (x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-oAn211OnOg",
        "outputId": "351ded66-52b4-4cfd-a67c-9b3460b59ec1"
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT4RWCMSDSg0"
      },
      "source": [
        "\n",
        "class Autoencoder(Model):\n",
        "  def __init__(self):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(32, activation='relu')\n",
        "      #for more layers\n",
        "      #layers.Dense(256, activation='relu'),\n",
        "      #layers.Dense(128, activation='relu'),\n",
        "      #layers.Dense(64, activation='relu'),\n",
        "      #layers.Dense(32, activation='relu')\n",
        "    ])\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(128, activation='relu'),                                  \n",
        "      layers.Dense(784, activation='relu'),\n",
        "      #for more layers\n",
        "      #layers.Dense(64, activation='relu'),\n",
        "      #layers.Dense(128, activation='relu'),\n",
        "      #layers.Dense(256, activation='relu'),\n",
        "      #layers.Dense(784, activation='relu')\n",
        "      layers.Reshape((28, 28))\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = Autoencoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVqQc2D_DZ8m"
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnLd7pngDcOL",
        "outputId": "0ec74660-3d3d-4367-e0ca-0b52a5e02d45"
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=30,\n",
        "                shuffle=True,\n",
        "                batch_size=256,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "235/235 [==============================] - 3s 5ms/step - loss: 0.0810 - val_loss: 0.0289\n",
            "Epoch 2/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0272 - val_loss: 0.0248\n",
            "Epoch 3/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0243 - val_loss: 0.0233\n",
            "Epoch 4/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0228 - val_loss: 0.0222\n",
            "Epoch 5/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0219 - val_loss: 0.0215\n",
            "Epoch 6/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0213 - val_loss: 0.0208\n",
            "Epoch 7/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0205 - val_loss: 0.0203\n",
            "Epoch 8/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0201 - val_loss: 0.0199\n",
            "Epoch 9/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0198 - val_loss: 0.0197\n",
            "Epoch 10/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0195 - val_loss: 0.0194\n",
            "Epoch 11/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0190 - val_loss: 0.0188\n",
            "Epoch 12/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - val_loss: 0.0185\n",
            "Epoch 13/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0183 - val_loss: 0.0181\n",
            "Epoch 14/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0179 - val_loss: 0.0181\n",
            "Epoch 15/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0177 - val_loss: 0.0179\n",
            "Epoch 16/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0176 - val_loss: 0.0177\n",
            "Epoch 17/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0175 - val_loss: 0.0176\n",
            "Epoch 18/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0173 - val_loss: 0.0173\n",
            "Epoch 19/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0171 - val_loss: 0.0172\n",
            "Epoch 20/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0170 - val_loss: 0.0171\n",
            "Epoch 21/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0169 - val_loss: 0.0171\n",
            "Epoch 22/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0168 - val_loss: 0.0170\n",
            "Epoch 23/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0167 - val_loss: 0.0168\n",
            "Epoch 24/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0167 - val_loss: 0.0167\n",
            "Epoch 25/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0166 - val_loss: 0.0167\n",
            "Epoch 26/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0166 - val_loss: 0.0167\n",
            "Epoch 27/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0165 - val_loss: 0.0167\n",
            "Epoch 28/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0164 - val_loss: 0.0166\n",
            "Epoch 29/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0164 - val_loss: 0.0166\n",
            "Epoch 30/30\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0164 - val_loss: 0.0165\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f53103d3390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz1xpni_Q9Ke"
      },
      "source": [
        "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "WIQQ29tkDlrq",
        "outputId": "2526efeb-a298-4948-d3aa-fb5be86eb295"
      },
      "source": [
        "n = 2\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i in range(n):\n",
        "  # display original\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  plt.imshow(x_test[i])\n",
        "  plt.title(\"original\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  # display reconstruction\n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  plt.imshow(decoded_imgs[i])\n",
        "  plt.title(\"reconstructed\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mxVZ7w4neXY"
      },
      "source": [
        "### SVM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiAh5BYdRSVM"
      },
      "source": [
        "train_vectors = autoencoder.encoder(x_train).numpy()\n",
        "test_vectors = autoencoder.encoder(x_test).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apAEtL7whrRh",
        "outputId": "0c973ff6-9775-4238-ce8f-ec34333f17d5"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "clf = SVC()\n",
        "\n",
        "# defining parameter range\n",
        "param_grid = {'C': [0.1, 1, 10, 100], \n",
        "               'kernel': ['linear', 'rbf']} \n",
        "\n",
        "# for test\n",
        "#param_grid = {'C': [0.1], \n",
        "#               'kernel': ['linear']} \n",
        "  \n",
        "grid = GridSearchCV(clf, param_grid, verbose = 1, refit = True)\n",
        "  \n",
        "# fitting the model for grid search\n",
        "grid.fit(train_vectors, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.1], 'kernel': ['linear']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0hzGg_FRh0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6ec8f1-aac5-4f0d-e710-0fa2e522a3cc"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)\n",
        "\n",
        "grid_predictions = grid.predict(test_vectors)\n",
        "# print classification report\n",
        "print(classification_report(y_test, grid_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': 0.1, 'kernel': 'linear'}\n",
            "SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.83      0.78      1000\n",
            "           1       0.98      0.95      0.97      1000\n",
            "           2       0.71      0.69      0.70      1000\n",
            "           3       0.84      0.86      0.85      1000\n",
            "           4       0.71      0.73      0.72      1000\n",
            "           5       0.94      0.90      0.92      1000\n",
            "           6       0.56      0.48      0.52      1000\n",
            "           7       0.89      0.93      0.91      1000\n",
            "           8       0.94      0.94      0.94      1000\n",
            "           9       0.93      0.93      0.93      1000\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eCt6Jz_nrpF"
      },
      "source": [
        "# CNN-based Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IakF9f5rkHSh"
      },
      "source": [
        "class Con_Autoencoder(Model):\n",
        "  def __init__(self):\n",
        "    super(Con_Autoencoder, self).__init__() \n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Conv2D(16, (3, 3), strides=(1, 1), activation='relu', padding='same'),\n",
        "      layers.Conv2D(8, (3, 3), strides=(1, 1), activation='relu', padding='same'),\n",
        "      layers.MaxPooling2D((2, 2))\n",
        "    ])\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Conv2D(8, (3, 3), strides=(1, 1), activation='relu', padding='same'),\n",
        "      layers.Conv2D(16, (3, 3), strides=(1, 1), activation='relu', padding='same'),\n",
        "      layers.UpSampling2D((2, 2)),\n",
        "      #layers.Reshape((28, 28))\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = Con_Autoencoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J-_mTxsnVzP"
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L76rQMz3lBn"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLn-9oF-nX33"
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                batch_size=256,\n",
        "                epochs=15,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m-jcuU7n9AB"
      },
      "source": [
        "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCkgrIknn_Ld"
      },
      "source": [
        "n = 2\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i in range(n):\n",
        "  # display original\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  plt.imshow(x_test[i][:,:,0])\n",
        "  plt.title(\"original\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  # display reconstruction\n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  plt.imshow(decoded_imgs[i][:,:,0])\n",
        "  plt.title(\"reconstructed\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}