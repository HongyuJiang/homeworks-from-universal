{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (system-wide)",
      "language": "python",
      "metadata": {
        "cocalc": {
          "description": "Python 3 programming language",
          "priority": 100,
          "url": "https://www.python.org/"
        }
      },
      "name": "python3",
      "resource_dir": "/ext/jupyter/kernels/python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Nsci0007 Group Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "P7BRRtDOvMDY"
      },
      "source": [
        "# MRI Segmentation #\n",
        "\n",
        "## Motivation ##\n",
        "In 2017, dementia became the biggest killer in the UK, overcoming vastly feared diseases such as heart disease and cancer, being responsible for a devastating 70,366 deaths in Britain alone. Dementia is a group of diseases characterised by cognitive impairment, which has two common symptoms; memory loss and clouded judgement, this can advance to an extent that makes it difficult for patients to execute normal daily tasks such as going to work or even preparing a meal. Alzheimer’s disease (AD) is the most common type of senile dementia in the UK. AD is a neurodegenerative disease that was named after the German clinical psychiatrist and neuroanatomist, Alois Alzheimer, who on November 3rd, 1906 reported “A peculiar severe disease process of the cerebral cortex”, being the first person to describe the disease’s symptoms and common hallmarks, the infamous beta amyloid plaques (Aβ plaques) and neurofibrillary tangles. These plaques and tangles described by Alois Alzheimer impair the functioning of previously healthy neurons which lose synaptic connections to one another and eventually die. Initially, the part of the brain that suffers the most from these changes is the hippocampus, which is essential for the formation of new memories. The death of neurons then spreads across the brain, resulting in atrophy of the white matter, as the gyri decrease in size, and the vacuoles and sulci to become larger, thus the cross-section of the brain becomes significantly smaller as the disease progresses. All these changes in the structure of the brain lead to the symptoms commonly related to AD such as forgetting a family member’s name or finding it hard to locate themselves. This atrophy of the white matter results in a grey matter to white matter ratio that is distinguishable to that of a 'healthy' brain. The purpose of this project is to provide an automated way of diagnosing AD through this grey matter to white matter ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpAzaeva6__Y",
        "outputId": "721fa3a6-2c9c-44b4-93c0-4d2f3ff2cf1d"
      },
      "source": [
        "# Load the Drive helper and mount\r\n",
        "from google.colab import drive\r\n",
        "\r\n",
        "# This will prompt for authorization.\r\n",
        "drive.mount('/content/drive')\r\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdrSoORkh29q"
      },
      "source": [
        "# 安装第三方脑区提取工具\r\n",
        "pip install git+https://github.com/rockstreamguy/deepbrain.git#egg=deepbrain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "xOi_oS1_vMDd"
      },
      "source": [
        "## Helper for Otsu Algorithm ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fxn3e3tvX_3"
      },
      "source": [
        "from __future__ import absolute_import\r\n",
        "from __future__ import division\r\n",
        "from __future__ import print_function\r\n",
        "\r\n",
        "import cv2\r\n",
        "import pylab as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def varianceCalculate(average, histgram):\r\n",
        "    #计算方差\r\n",
        "    variance = 0\r\n",
        "    for i in range(len(histgram)):\r\n",
        "        variance += (histgram[i] - average) ** 2\r\n",
        "\r\n",
        "    variance /= len(histgram)\r\n",
        "\r\n",
        "    return variance\r\n",
        "\r\n",
        "def averageAndpixelSumCalculate(histgram):\r\n",
        "    #计算全部像素的平均值\r\n",
        "    average = pixelSum = 0\r\n",
        "    for i in range(len(histgram)):\r\n",
        "        pixelSum += histgram[i]         #像素总数\r\n",
        "        brightnessValue = histgram[i] * i   #辉度计算\r\n",
        "\r\n",
        "    average = brightnessValue / len(histgram)\r\n",
        "\r\n",
        "    return pixelSum, average\r\n",
        "\r\n",
        "def within_betweenCV(pixelSum1, average1, variance1, pixelSum2, average2, variance2):\r\n",
        "    #返回类间分布和类内分布\r\n",
        "\r\n",
        "    betweenClassVariance = (pixelSum1 * pixelSum2 * ((average1 - average2) ** 2) ) / ((pixelSum1 + pixelSum2) ** 2) #类间分布\r\n",
        "    withinClassVariance = (pixelSum1 * variance1 + pixelSum2 * variance2) / (pixelSum1 + pixelSum2) #类内分布\r\n",
        "\r\n",
        "    return betweenClassVariance, withinClassVariance\r\n",
        "\r\n",
        "def calculateAll(blackList, whiteList):\r\n",
        "    #执行计算过程\r\n",
        "    b_size, b_average = averageAndpixelSumCalculate(blackList)\r\n",
        "    w_size, w_average = averageAndpixelSumCalculate(whiteList)\r\n",
        "\r\n",
        "    b_variance = varianceCalculate(b_average, blackList)\r\n",
        "    w_variance = varianceCalculate(w_average, whiteList)\r\n",
        "\r\n",
        "    betweenCV, withinCV = within_betweenCV(b_size, b_average, b_variance, w_size, w_average, w_variance)\r\n",
        "\r\n",
        "    totalVariance = betweenCV + withinCV #总方差\r\n",
        "    separationMetrics = betweenCV / (totalVariance - betweenCV) #类间方差与类内方差的比率\r\n",
        "\r\n",
        "    return separationMetrics\r\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYlsvE2_XTKj"
      },
      "source": [
        "## Functions for brain extraction and segmentation ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxlELmNIvVaf"
      },
      "source": [
        "def brain_extraction(volume):\r\n",
        "  # 调用第三方算法对脑区进行提取\r\n",
        "  # 详细见https://github.com/rockstreamguy/deepbrain\r\n",
        "\r\n",
        "  ext = Extractor()\r\n",
        "  prob = ext.run(volume) \r\n",
        "  mask = prob > 0.5\r\n",
        "  brain_volume = np.multiply(mask, volume)\r\n",
        "\r\n",
        "  return brain_volume\r\n",
        "\r\n",
        "def find_threshold(img):\r\n",
        "  # 找到最佳分割阈值\r\n",
        "\r\n",
        "  #计算直方图\r\n",
        "  hist, bin_edges = np.histogram(img, bins=256, range=[0, 256], density=True)\r\n",
        "  \r\n",
        "  #计算分离度\r\n",
        "  size = 256\r\n",
        "  listSM = [0 for i in range(size)]                       \r\n",
        "  for i in range(size):\r\n",
        "    if i != 0 and i != size-1:\r\n",
        "      blackList = hist[0: i]                    #亮度较低的部分\r\n",
        "      whiteList = hist[i: size]                   #亮度较高的部分\r\n",
        "      listSM[i] = calculateAll(blackList, whiteList)         #分散度\r\n",
        "    elif i == 0 or i == size-1:\r\n",
        "      listSM[i] = 0                           #无法将其分为两个列表时的异常处理\r\n",
        "\r\n",
        "  #从最大分离度中找到阈值\r\n",
        "  maxValue = 0\r\n",
        "  maxValueIndex = 0\r\n",
        "\r\n",
        "  #保存最大分散值的索引\r\n",
        "  for i in range(size):   \r\n",
        "    if listSM[i] > maxValue:\r\n",
        "      maxValue = listSM[i]\r\n",
        "      maxValueIndex = i     \r\n",
        "\r\n",
        "  return hist, maxValueIndex\r\n",
        "\r\n",
        "def binarization_otsu(img, maxValueIndex):\r\n",
        "  #根据获得的阈值对图像进行二值化\r\n",
        "  output_otsu = np.zeros((len(img), len(img[0])))    #使用数组输出大津法的结果\r\n",
        "  for i in range(len(img)):\r\n",
        "    for j in range(len(img[0])):\r\n",
        "      if img[i][j] > maxValueIndex:\r\n",
        "        output_otsu[i][j] = 255      #大于阈值的部分设为黑色\r\n",
        "      else:\r\n",
        "        output_otsu[i][j] = 0       #小于阈值的部分设为白色\r\n",
        "  return output_otsu\r\n",
        "\r\n",
        "def binarization_avg(img, hist):\r\n",
        "  #以直方图中亮度值的中间值作为阈值创建二值化图像\r\n",
        "  average_histgram = int(len(hist) / 2)           #获取直方图长度的一半\r\n",
        "  output_average = img.copy()                #用于简单二值化输出的阵列\r\n",
        "  output_average[output_average >= average_histgram] = 255  \r\n",
        "  output_average[output_average < average_histgram] = 0        #小于阈值的部分设为白色\r\n",
        "  \r\n",
        "  return output_average\r\n",
        "\r\n",
        "from skimage.morphology import erosion, opening\r\n",
        "from skimage.morphology import disk\r\n",
        "\r\n",
        "def result_improvement(origin):\r\n",
        "  #基于形态学操作对图形进行微调\r\n",
        "  #操作列表见 https://scikit-image.org/docs/dev/auto_examples/applications/plot_morphology.html\r\n",
        "\r\n",
        "  #形态学操作基本单元设置\r\n",
        "  selem = disk(1)\r\n",
        "\r\n",
        "  #得到腐蚀操作结果\r\n",
        "  erosed = erosion(origin, selem)\r\n",
        "\r\n",
        "  #二值化\r\n",
        "  for i in range(len(erosed)):\r\n",
        "    for j in range(len(erosed[0])):\r\n",
        "      if erosed[i][j] > 0:\r\n",
        "        erosed[i][j] = 255      #大于阈值的部分设为黑色\r\n",
        "      else:\r\n",
        "        erosed[i][j] = 0       #小于阈值的部分设为白色\r\n",
        "\r\n",
        "  return erosed\r\n",
        "\r\n",
        "def show_comparison(origin, brain, otsu):\r\n",
        "  #显示大脑提取，大脑分割结果\r\n",
        "  fig, ax = plt.subplots(2, 2, figsize=(10,10))\r\n",
        "\r\n",
        "  #隐藏网格线\r\n",
        "  plt.ioff()\r\n",
        "  plt.grid(False)\r\n",
        "  plt.grid(b=None)\r\n",
        "\r\n",
        "  ax[0, 0].imshow(origin, cmap='gray')        #原图\r\n",
        "  ax[0, 0].grid(False)\r\n",
        "\r\n",
        "  brain[brain > 0] = 255\r\n",
        "  ax[0, 1].imshow(brain, cmap='gray')         #大脑提取\r\n",
        "  ax[0, 1].grid(False)  \r\n",
        "\r\n",
        "  ax[1, 0].imshow(otsu, cmap='gray')         #大津法阈值\r\n",
        "  ax[1, 0].grid(False)\r\n",
        "\r\n",
        "  ax[1, 1].imshow(origin, cmap='gray')        #堆叠图\r\n",
        "  ax[1, 1].imshow(otsu, 'jet', alpha=0.5)      \r\n",
        "  ax[1, 1].grid(False)\r\n",
        "  plt.savefig('hehe.png')\r\n",
        "  plt.close(fig)\r\n",
        "\r\n",
        "\r\n",
        "def calcWGRatio(whole_img, white_img):\r\n",
        "\r\n",
        "  # 计算图像中白点和黑点的数量\r\n",
        "  greyCount = 0\r\n",
        "  whiteCount = 0\r\n",
        "\r\n",
        "  for i in range(len(whole_img)):\r\n",
        "    for j in range(len(whole_img[0])):\r\n",
        "      if whole_img[i][j] == 255:\r\n",
        "        if whole_img[i][j] == white_img[i][j]:\r\n",
        "          whiteCount += 1\r\n",
        "        else:\r\n",
        "          greyCount += 1\r\n",
        "  \r\n",
        "  return whiteCount, greyCount\r\n"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81iDO06DXbPS"
      },
      "source": [
        "## Main process flow ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcVXXN1547xl",
        "outputId": "ec4f5282-2970-46f5-99ee-233060a9e3e7"
      },
      "source": [
        "import numpy as np\r\n",
        "import nibabel as nib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "from deepbrain import Extractor\r\n",
        "from google.colab import output\r\n",
        "\r\n",
        "sns.set_style('darkgrid')\r\n",
        "\r\n",
        "img_1_1 = nib.load('/content/drive/MyDrive/Road Recommendation/subject1_01.nii')\r\n",
        "img_data_1_1 = img_1_1.get_fdata()\r\n",
        "\r\n",
        "brain_volume = brain_extraction(img_data_1_1)\r\n",
        "slice_num = list(brain_volume.shape)[2]\r\n",
        "total_white_num = 0\r\n",
        "total_grey_num = 0\r\n",
        "\r\n",
        "for i in range(slice_num):\r\n",
        "\r\n",
        "  output.clear()\r\n",
        "  print('Now computing ' + str(i) + 'th of total ' + str(slice_num) + ' brain slices')\r\n",
        "\r\n",
        "  b_slice = brain_volume[:, :, i]\r\n",
        "\r\n",
        "  # 使用大津算法得到最佳阈值\r\n",
        "  hist, threshold_index = find_threshold(b_slice)\r\n",
        "\r\n",
        "  # 使用大津算法得到的最佳阈值进行图像二值化\r\n",
        "  binary_otsu = binarization_otsu(b_slice, threshold_index)\r\n",
        "\r\n",
        "  # 得到形态学微调结果 (可选)\r\n",
        "  improved_img = result_improvement(binary_otsu)\r\n",
        "\r\n",
        "  # 存储或者显示图像\r\n",
        "  show_comparison(img_data_1_1[:, :, i], b_slice, improved_img)\r\n",
        "\r\n",
        "  # 分别计算白点和黑点的数量\r\n",
        "  whiteNum, greyNum = calcWGRatio(b_slice, improved_img)\r\n",
        "  \r\n",
        "  total_white_num += whiteNum\r\n",
        "  total_grey_num += greyNum\r\n",
        "\r\n",
        "# 输出最终结果\r\n",
        "print('Ratio of grey matter to white matter ' + str(total_grey_num / total_white_num))\r\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now computing 123th of total 124 brain slices\n",
            "Ratio of grey matter to white matter 2.0934071628827726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7-tQYDKXnyA"
      },
      "source": [
        "## For visualize the otsu's result in histogram ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq-IaW4hBtdb"
      },
      "source": [
        "def plot_hist(hist, maxValueIndex):\r\n",
        "\r\n",
        "  #输出直方图\r\n",
        "  plt.plot(hist)                                      \r\n",
        "  plt.axvline(x=maxValueIndex, color='red', label='otsu')          #大津法阈值显示\r\n",
        "  plt.axvline(x=average_histgram, color='green', label='average')      #静态阈值显示\r\n",
        "  plt.legend(loc='upper right')                       \r\n",
        "  plt.title(\"histgram of brightness\")                    \r\n",
        "  plt.xlabel(\"brightness\")                             \r\n",
        "  plt.ylabel(\"frequency\")                               \r\n",
        "  plt.xlim([0, 256])                     \r\n",
        "  plt.show()\r\n"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "1NVgYWB6vMDe"
      },
      "source": [
        "## The separation of white and grey matter ##\n",
        "\n",
        "In order to analyse the ratio of white and grey matter inside each  patients brain the respective regions must be separated.\n",
        "\n",
        "Over the years there have been many techniques developed to allow people to convert normal greyscale images into binary images (black and white). The complexity and accuracy of these techniques vary rather a lot.\n",
        "\n",
        "In this project we hope to use Otsu's method of image segmentation to binarise the MRI scans of patients one and two, thus allowing the simple comparison of white to grey matter ratios to take place.\n",
        "\n",
        "\n",
        "\n",
        "Otsu's method is essentially just an algorithm that finds the optimal threshold intensity (the optimal point at which to start calling the background the foreground).\n",
        "\n",
        "To do this it calculates something called the between class variance (${σ_b}^2$):\n",
        "\n",
        "$ {σ_b}^2 = W_b*W_f*(μ_b - μ_f)^2 $\n",
        "\n",
        "\n",
        "subscripts b and f denote background and foreground respectively.\n",
        "\n",
        "W stands for the weight which is simply the number of pixels in the given section divided by the total number of pixels.\n",
        "\n",
        "\n",
        "μ stands for the mean intensity, given by the following equation:\n",
        "\n",
        "\n",
        "$ μ_b = Σ (GL*Intensity) / n.pix_b $\n",
        "\n",
        "where GL stands for the grey level (a completely black pixel has a GL value of 0, lighter pixels having larger and larger GL values)\n",
        "\n",
        "\n",
        "Putting all of these components into the between class variance equation a value is obtained, the algorithm then repeats this for every possible threshold level. The level that gives the largest between class variance is taken as the best possible threshold level for turning a grey scale image into a binary one.\n",
        "\n"
      ]
    }
  ]
}